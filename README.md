# Introduction
A method is proposed which is a multi-scale feature representation based on the Cross-Attention Transformer.(CAPose)

# Start
## 1. Dependencies installation & data preparation
Please refer to [HRNet](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch) to prepare the environment and data  step by step. You need to GPUs whose capacity is  **over 48G** to train the model.
## Train

## Test

# Citations
If you use our code or models in your research, please give it a star or cite with:
```
@article{
  title={Cross Attention Transformer for Human Pose Estimation},
  author={WANG Kuan, XUAN Shibin, HE Xuedong, LI Ziwei and LI Jiaxiang},
}
```
# Acknowledgement
Thanks for the open-source:
> [HRNet](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch/), [TokenPose](https://github.com/leeyegy/TokenPose), [CrossVit](https://github.com/IBM/CrossViT.)
